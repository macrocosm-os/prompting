import random
from typing import ClassVar, Literal

from loguru import logger

from prompting.datasets.random_website import DDGDatasetEntry
from prompting.rewards.MSRv2_reward import MSRv2RewardModel
from prompting.rewards.reward import BaseRewardConfig, BaseRewardModel
from prompting.tasks.multi_step_reasoning import MultiStepReasoningTask
from shared.base import Context


class MSRv2RewardConfig(BaseRewardConfig):
    reward_definitions: ClassVar[list[BaseRewardModel]] = [
        MSRv2RewardModel(weight=1),
    ]


class MSRv2Task(MultiStepReasoningTask):
    """QuestionAnsweringTasks must be initialised with an LLM pipeline to generate query and reference plus
    context from a dataset to base the query on"""

    name: ClassVar[str] = "multi_step_reasoning_v2"
    augmentation_system_prompt: ClassVar[str] = ""
    generative_miner_answer: str | None = None
    reference: str | None = None
    REAL_REFERENCE_PROBABILITY: float = 0.1
    generator_uid: int | None = None

    @property
    def stage(self) -> Literal["generative", "discriminative"]:
        if self.generative_miner_answer or self.reference:
            return "discriminative"
        return "generative"

    @property
    def ground_truth(self) -> int | None:
        """Returns 1 if the reference was generated by the validator, 0 if it was generated by the miner"""
        if self.reference:
            return 1
        elif self.generative_miner_answer:
            return 0
        logger.error("No ground truth for MSRv2Task available yet")
        return None

    def make_query(self, dataset_entry: DDGDatasetEntry):
        if self.stage == "generative":
            # Question to send to miner
            self.query = super().make_query(dataset_entry)
            # Wrapped Query
            self.messages = [{"role": "user", "content": self.query}]
            return self.query

        return self.reference or self.generative_miner_answer

    async def make_reference(self, dataset_entry: Context):
        if self.stage == "generative":
            # Generates a real reference with probability REAL_REFERENCE_PROBABILITY, otherwise waits for miner to generate an answer
            if random.random() < self.REAL_REFERENCE_PROBABILITY:
                return super().make_reference(dataset_entry)
            else:
                return self.reference
        else:
            # return 1 if it's validator generated, 0 if it's miner generated
            return 1 if self.reference else 0

    @property
    def request_body(self) -> dict:
        body = super().request_body
        # By sending this over, we can allow miners to scale their prediction based on the probability of the reference being real
        # so that validators can adjust the probability based on load in later iterations
        body["real_reference_probability"] = self.REAL_REFERENCE_PROBABILITY
        body["stage"] = self.stage
        # if we're in the discriminative stage, we need to send the messages and the miner's answer, otherwise we just send the query
        if self.stage == "discriminative":
            body["messages"] = self.messages + [
                {"role": "assistant", "content": self.reference or self.generative_miner_answer}
            ]
        return body
