import random
from typing import ClassVar

from loguru import logger

from prompting.datasets.random_website import DDGDatasetEntry
from typing import Literal
from prompting.rewards.relevance import RelevanceRewardModel
from prompting.rewards.reward import BaseRewardConfig, BaseRewardModel
from prompting.tasks.multi_step_reasoning import MultiStepReasoningTask
from shared.base import Context
from validator_api.test_time_inference import generate_response

MAX_THINKING_STEPS = 10

class MSRv2Task(MultiStepReasoningTask):
    """QuestionAnsweringTasks must be initialised with an LLM pipeline to generate query and reference plus
    context from a dataset to base the query on"""

    name: ClassVar[str] = "multi_step_reasoning_v2"
    augmentation_system_prompt: ClassVar[str] = ""
    generative_miner_answer: str | None = None
    reference_answer: str | None = None
    REAL_REFERENCE_PROBABILITY: float = 0.1
    generator_uid: int | None = None

    @property
    def stage(self) -> Literal["generative", "discriminative"]:
        if self.generative_miner_answer or self.reference_answer:
            return "discriminative"
        return "generative"

    @property
    def ground_truth(self) -> int | None:
        """Returns 1 if the reference was generated by the validator, 0 if it was generated by the miner"""
        if self.reference_answer:
            return 1
        elif self.generative_miner_answer:
            return 0
        logger.error("No ground truth for MSRv2Task available yet")
        return None

    def make_query(self, dataset_entry: DDGDatasetEntry):
        if self.stage == "generative":
            self.query = super().make_query(dataset_entry)
            self.messages = [{"role": "user", "content": self.query}]

        return self.generative_miner_answer or self.reference_answer

    async def make_reference(self, dataset_entry: Context):
        if self.stage == "generative":
            # Generates a real reference with probability REAL_REFERENCE_PROBABILITY, otherwise waits for miner to generate an answer 
            if random.random() < self.REAL_REFERENCE_PROBABILITY:
                return super().make_reference(dataset_entry)
            else:
                return None
        else:
            # return 1 if it's validator generated, 0 if it's miner generated
            return 1 if self.reference_answer else 0
    
    @property
    def request_body(self) -> dict:
        body = super().request_body
        

        # By sending this over, we can allow miners to scale their prediction based on the probability of the reference being real
        # so that validators can adjust the probability based on load in later iterations
        body["real_reference_probability"] = self.REAL_REFERENCE_PROBABILITY         
        body["stage"] = self.stage
        # if we're in the discriminative stage, we need to send the messages and the miner's answer, otherwise we just send the query
        if self.stage == "discriminative":
            body["messages"] = self.messages + [{"role": "assistant", "content": self.generative_miner_answer or self.reference_answer}]
        return body